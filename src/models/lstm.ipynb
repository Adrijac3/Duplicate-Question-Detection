{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpGQq9WIo-Fk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnBsiT5KXyNc"
      },
      "source": [
        "## Importing relevant modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omFH7YA9Jap_"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7d-D65RIqVN"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/questions.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAvi7Q1yLdrk",
        "outputId": "89919028-c06d-4139-bb80-962560db7a67"
      },
      "source": [
        "labels = df[\"is_duplicate\"]\n",
        "labels"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "404346    0\n",
              "404347    1\n",
              "404348    0\n",
              "404349    0\n",
              "404350    0\n",
              "Name: is_duplicate, Length: 404351, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWG9qBPJX3XJ"
      },
      "source": [
        "## Splitting data into train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVeFuPF4K_6x"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=df.to_numpy()\n",
        "y=np.asarray(labels)\n",
        "X_train,X_test,y_train,y_test=train_test_split(df,labels,test_size=0.1,random_state=45)\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2, random_state=45)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUoVq9VLsbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca354194-ed16-48e3-9bfc-0abeb6daee93"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_validate.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_validate.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(291132, 6)\n",
            "(72783, 6)\n",
            "(40436, 6)\n",
            "(291132,)\n",
            "(72783,)\n",
            "(40436,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syUR8EiRX-qB"
      },
      "source": [
        "## Setting up Keras tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n_Xcl_SJPqJ"
      },
      "source": [
        "MAX_NB_WORDS = 200\n",
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(list(X_train['question1'].values.astype(str))+list(X_train['question2'].values.astype(str)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK0WkRwaYlrH"
      },
      "source": [
        "## Creating feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug2O5BH9JyPJ"
      },
      "source": [
        "X_train_q1 = tokenizer.texts_to_sequences(X_train['question1'].values.astype(str))\n",
        "X_train_q1 = pad_sequences(X_train_q1, maxlen = 30, padding='post')\n",
        "X_train_q2 = tokenizer.texts_to_sequences(X_train['question2'].values.astype(str))\n",
        "X_train_q2 = pad_sequences(X_train_q2, maxlen = 30, padding='post')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9kqSaym5Mep"
      },
      "source": [
        "X_validate_q1 = tokenizer.texts_to_sequences(X_validate['question1'].values.astype(str))\n",
        "X_validate_q1 = pad_sequences(X_validate_q1, maxlen = 30, padding='post')\n",
        "X_validate_q2 = tokenizer.texts_to_sequences(X_validate['question2'].values.astype(str))\n",
        "X_validate_q2 = pad_sequences(X_validate_q2, maxlen = 30, padding='post')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CRlXkLqO7JC"
      },
      "source": [
        "X_test_q1 = tokenizer.texts_to_sequences(X_test['question1'].values.astype(str))\n",
        "X_test_q1 = pad_sequences(X_test_q1,maxlen = 30, padding='post')\n",
        "\n",
        "X_test_q2 = tokenizer.texts_to_sequences(X_test['question2'].values.astype(str))\n",
        "X_test_q2 = pad_sequences(X_test_q2, maxlen = 30, padding='post')\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SmvgwFuYq-G"
      },
      "source": [
        "## Creating dictionary of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeNKmUM0Mh28",
        "outputId": "8fed1e42-d933-4ec1-9f70-a778dc991fef"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "word_index"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'what': 2,\n",
              " 'is': 3,\n",
              " 'how': 4,\n",
              " 'i': 5,\n",
              " 'a': 6,\n",
              " 'to': 7,\n",
              " 'in': 8,\n",
              " 'do': 9,\n",
              " 'of': 10,\n",
              " 'are': 11,\n",
              " 'and': 12,\n",
              " 'can': 13,\n",
              " 'for': 14,\n",
              " 'you': 15,\n",
              " 'why': 16,\n",
              " 'best': 17,\n",
              " 'my': 18,\n",
              " 'it': 19,\n",
              " 'on': 20,\n",
              " 'does': 21,\n",
              " 'or': 22,\n",
              " 'which': 23,\n",
              " 'if': 24,\n",
              " 'be': 25,\n",
              " 'some': 26,\n",
              " 'have': 27,\n",
              " 'that': 28,\n",
              " 'with': 29,\n",
              " 'get': 30,\n",
              " 'should': 31,\n",
              " 'an': 32,\n",
              " 'from': 33,\n",
              " 'your': 34,\n",
              " 'india': 35,\n",
              " 'will': 36,\n",
              " 'when': 37,\n",
              " 'people': 38,\n",
              " 'like': 39,\n",
              " 'who': 40,\n",
              " 'at': 41,\n",
              " 'good': 42,\n",
              " 'would': 43,\n",
              " 'there': 44,\n",
              " 'as': 45,\n",
              " 'about': 46,\n",
              " 'not': 47,\n",
              " 'between': 48,\n",
              " 'one': 49,\n",
              " 'most': 50,\n",
              " 'we': 51,\n",
              " 'make': 52,\n",
              " 'did': 53,\n",
              " 'quora': 54,\n",
              " 'way': 55,\n",
              " 'where': 56,\n",
              " 'by': 57,\n",
              " 'any': 58,\n",
              " 'was': 59,\n",
              " 'life': 60,\n",
              " 'me': 61,\n",
              " 'so': 62,\n",
              " 'after': 63,\n",
              " 'time': 64,\n",
              " 'they': 65,\n",
              " 'this': 66,\n",
              " 'money': 67,\n",
              " 'know': 68,\n",
              " 'difference': 69,\n",
              " 'has': 70,\n",
              " 'learn': 71,\n",
              " 'am': 72,\n",
              " 'new': 73,\n",
              " 'much': 74,\n",
              " \"what's\": 75,\n",
              " 'use': 76,\n",
              " 'their': 77,\n",
              " 'think': 78,\n",
              " 'many': 79,\n",
              " 'work': 80,\n",
              " 'all': 81,\n",
              " 'indian': 82,\n",
              " 'someone': 83,\n",
              " 'find': 84,\n",
              " 'ever': 85,\n",
              " 'than': 86,\n",
              " 'more': 87,\n",
              " 'without': 88,\n",
              " 'but': 89,\n",
              " 'become': 90,\n",
              " 'trump': 91,\n",
              " 'start': 92,\n",
              " 'better': 93,\n",
              " 'online': 94,\n",
              " 'other': 95,\n",
              " 'world': 96,\n",
              " 'first': 97,\n",
              " 'out': 98,\n",
              " 'want': 99,\n",
              " 'year': 100,\n",
              " 'mean': 101,\n",
              " 'job': 102,\n",
              " '2': 103,\n",
              " 'english': 104,\n",
              " 'us': 105,\n",
              " 'up': 106,\n",
              " 'into': 107,\n",
              " 'feel': 108,\n",
              " \"don't\": 109,\n",
              " 'take': 110,\n",
              " 'love': 111,\n",
              " '2016': 112,\n",
              " 'could': 113,\n",
              " '1': 114,\n",
              " 'he': 115,\n",
              " 'day': 116,\n",
              " 'possible': 117,\n",
              " 'questions': 118,\n",
              " 'things': 119,\n",
              " 'go': 120,\n",
              " 'notes': 121,\n",
              " '500': 122,\n",
              " 'ways': 123,\n",
              " 'phone': 124,\n",
              " 'really': 125,\n",
              " 'engineering': 126,\n",
              " 'were': 127,\n",
              " 'buy': 128,\n",
              " 'account': 129,\n",
              " 'used': 130,\n",
              " 'weight': 131,\n",
              " '1000': 132,\n",
              " '3': 133,\n",
              " 'long': 134,\n",
              " 'donald': 135,\n",
              " 'person': 136,\n",
              " 'old': 137,\n",
              " 'google': 138,\n",
              " 'girl': 139,\n",
              " 'them': 140,\n",
              " \"i'm\": 141,\n",
              " 'number': 142,\n",
              " 'her': 143,\n",
              " 'being': 144,\n",
              " 'improve': 145,\n",
              " 'using': 146,\n",
              " 'business': 147,\n",
              " 'his': 148,\n",
              " 'books': 149,\n",
              " 'need': 150,\n",
              " 'facebook': 151,\n",
              " 'language': 152,\n",
              " 'lose': 153,\n",
              " 'movie': 154,\n",
              " 'black': 155,\n",
              " 'sex': 156,\n",
              " 'stop': 157,\n",
              " 'different': 158,\n",
              " 'thing': 159,\n",
              " 'been': 160,\n",
              " 'book': 161,\n",
              " 'free': 162,\n",
              " 'now': 163,\n",
              " 'war': 164,\n",
              " 'just': 165,\n",
              " 'compare': 166,\n",
              " 'question': 167,\n",
              " 'see': 168,\n",
              " '5': 169,\n",
              " 'years': 170,\n",
              " 'going': 171,\n",
              " 'no': 172,\n",
              " 'still': 173,\n",
              " 'programming': 174,\n",
              " 'help': 175,\n",
              " 'happen': 176,\n",
              " 'change': 177,\n",
              " 'president': 178,\n",
              " 'only': 179,\n",
              " 'had': 180,\n",
              " 'movies': 181,\n",
              " 'app': 182,\n",
              " 'instagram': 183,\n",
              " 'before': 184,\n",
              " 'company': 185,\n",
              " 'its': 186,\n",
              " 'college': 187,\n",
              " 'over': 188,\n",
              " 'under': 189,\n",
              " 'prepare': 190,\n",
              " 'real': 191,\n",
              " 'examples': 192,\n",
              " 'women': 193,\n",
              " 'android': 194,\n",
              " 'computer': 195,\n",
              " 'rs': 196,\n",
              " '10': 197,\n",
              " 'while': 198,\n",
              " 'live': 199,\n",
              " 'country': 200,\n",
              " 'website': 201,\n",
              " 'c': 202,\n",
              " 'bad': 203,\n",
              " 'ask': 204,\n",
              " 'iphone': 205,\n",
              " 'back': 206,\n",
              " 'she': 207,\n",
              " 'system': 208,\n",
              " 'learning': 209,\n",
              " 'win': 210,\n",
              " 'our': 211,\n",
              " 'study': 212,\n",
              " 'data': 213,\n",
              " 'important': 214,\n",
              " 'made': 215,\n",
              " 'through': 216,\n",
              " 'increase': 217,\n",
              " 'top': 218,\n",
              " 'same': 219,\n",
              " 'read': 220,\n",
              " 'school': 221,\n",
              " '4': 222,\n",
              " 'hillary': 223,\n",
              " 'science': 224,\n",
              " 'clinton': 225,\n",
              " 'math': 226,\n",
              " 's': 227,\n",
              " 'water': 228,\n",
              " 'two': 229,\n",
              " 'earn': 230,\n",
              " 'software': 231,\n",
              " 'card': 232,\n",
              " 'during': 233,\n",
              " 'mobile': 234,\n",
              " 'word': 235,\n",
              " 'student': 236,\n",
              " \"can't\": 237,\n",
              " 'government': 238,\n",
              " 'high': 239,\n",
              " 'energy': 240,\n",
              " 'say': 241,\n",
              " 'name': 242,\n",
              " 'exam': 243,\n",
              " 'give': 244,\n",
              " 'car': 245,\n",
              " 'anyone': 246,\n",
              " 'men': 247,\n",
              " 'getting': 248,\n",
              " 'university': 249,\n",
              " 'companies': 250,\n",
              " 'average': 251,\n",
              " 'right': 252,\n",
              " 'com': 253,\n",
              " 'true': 254,\n",
              " 'home': 255,\n",
              " 'then': 256,\n",
              " 'come': 257,\n",
              " 'days': 258,\n",
              " 'laptop': 259,\n",
              " 'career': 260,\n",
              " 'china': 261,\n",
              " 'earth': 262,\n",
              " 'web': 263,\n",
              " 'social': 264,\n",
              " 'even': 265,\n",
              " 'doing': 266,\n",
              " 'hair': 267,\n",
              " 'b': 268,\n",
              " 'look': 269,\n",
              " 'tell': 270,\n",
              " 'interview': 271,\n",
              " '2017': 272,\n",
              " 'video': 273,\n",
              " 'answer': 274,\n",
              " 'friend': 275,\n",
              " 'bank': 276,\n",
              " 'travel': 277,\n",
              " 'write': 278,\n",
              " 'usa': 279,\n",
              " 'meaning': 280,\n",
              " 'man': 281,\n",
              " 'password': 282,\n",
              " 'own': 283,\n",
              " 'him': 284,\n",
              " 'safe': 285,\n",
              " 'guy': 286,\n",
              " 'done': 287,\n",
              " 'eat': 288,\n",
              " 'food': 289,\n",
              " 'rupee': 290,\n",
              " 'watch': 291,\n",
              " 'students': 292,\n",
              " 'relationship': 293,\n",
              " 'youtube': 294,\n",
              " 'friends': 295,\n",
              " 'off': 296,\n",
              " 'game': 297,\n",
              " 'place': 298,\n",
              " 'working': 299,\n",
              " 'cost': 300,\n",
              " 'non': 301,\n",
              " 'having': 302,\n",
              " 'pakistan': 303,\n",
              " 'happens': 304,\n",
              " 'rid': 305,\n",
              " 'tv': 306,\n",
              " '6': 307,\n",
              " 'very': 308,\n",
              " 'experience': 309,\n",
              " 'u': 310,\n",
              " 'big': 311,\n",
              " 'mind': 312,\n",
              " 'x': 313,\n",
              " \"doesn't\": 314,\n",
              " 'girls': 315,\n",
              " 'whatsapp': 316,\n",
              " 'play': 317,\n",
              " 'service': 318,\n",
              " 'countries': 319,\n",
              " 'favorite': 320,\n",
              " 'future': 321,\n",
              " 'human': 322,\n",
              " 'major': 323,\n",
              " 'history': 324,\n",
              " '7': 325,\n",
              " 'affect': 326,\n",
              " 'myself': 327,\n",
              " 'white': 328,\n",
              " 'tech': 329,\n",
              " 'employees': 330,\n",
              " 'exist': 331,\n",
              " 'state': 332,\n",
              " 'tips': 333,\n",
              " 'every': 334,\n",
              " 'election': 335,\n",
              " 'engineer': 336,\n",
              " 'end': 337,\n",
              " 'download': 338,\n",
              " 'chinese': 339,\n",
              " 'too': 340,\n",
              " 'effects': 341,\n",
              " 'last': 342,\n",
              " 'process': 343,\n",
              " 'great': 344,\n",
              " 'age': 345,\n",
              " 'believe': 346,\n",
              " 'create': 347,\n",
              " 'email': 348,\n",
              " 'body': 349,\n",
              " 'against': 350,\n",
              " 'java': 351,\n",
              " 'skills': 352,\n",
              " 'makes': 353,\n",
              " 'differences': 354,\n",
              " 'marketing': 355,\n",
              " 'american': 356,\n",
              " 'class': 357,\n",
              " 'delhi': 358,\n",
              " 'hard': 359,\n",
              " 'test': 360,\n",
              " 'support': 361,\n",
              " 'internet': 362,\n",
              " 'next': 363,\n",
              " 'making': 364,\n",
              " 'mechanical': 365,\n",
              " 'places': 366,\n",
              " 'interesting': 367,\n",
              " 'visit': 368,\n",
              " 'police': 369,\n",
              " 'month': 370,\n",
              " 'girlfriend': 371,\n",
              " 'e': 372,\n",
              " 'states': 373,\n",
              " 'these': 374,\n",
              " 'got': 375,\n",
              " 'united': 376,\n",
              " 'pay': 377,\n",
              " 'god': 378,\n",
              " 'around': 379,\n",
              " 'salary': 380,\n",
              " 'market': 381,\n",
              " 'never': 382,\n",
              " 'music': 383,\n",
              " 'each': 384,\n",
              " 'actually': 385,\n",
              " 'keep': 386,\n",
              " 'song': 387,\n",
              " 'windows': 388,\n",
              " 'control': 389,\n",
              " 'worth': 390,\n",
              " 'looking': 391,\n",
              " 'power': 392,\n",
              " 'code': 393,\n",
              " '8': 394,\n",
              " 'course': 395,\n",
              " 'gmail': 396,\n",
              " 'america': 397,\n",
              " 'series': 398,\n",
              " 'available': 399,\n",
              " 'answers': 400,\n",
              " 'hotel': 401,\n",
              " 'fat': 402,\n",
              " 'universities': 403,\n",
              " 'common': 404,\n",
              " 'months': 405,\n",
              " 'considered': 406,\n",
              " 'culture': 407,\n",
              " 'development': 408,\n",
              " 'always': 409,\n",
              " 'woman': 410,\n",
              " 'delete': 411,\n",
              " 'parents': 412,\n",
              " 'modi': 413,\n",
              " 'site': 414,\n",
              " 'something': 415,\n",
              " 'another': 416,\n",
              " 'writing': 417,\n",
              " 'self': 418,\n",
              " 'mba': 419,\n",
              " 'per': 420,\n",
              " 'light': 421,\n",
              " 'die': 422,\n",
              " 'apply': 423,\n",
              " 'economy': 424,\n",
              " 'jobs': 425,\n",
              " 'idea': 426,\n",
              " \"you've\": 427,\n",
              " 'score': 428,\n",
              " 'happened': 429,\n",
              " 'problem': 430,\n",
              " 'universe': 431,\n",
              " 'dark': 432,\n",
              " 'open': 433,\n",
              " 'hack': 434,\n",
              " 'deal': 435,\n",
              " 'speed': 436,\n",
              " 'review': 437,\n",
              " 'education': 438,\n",
              " 'living': 439,\n",
              " 'games': 440,\n",
              " 'presidential': 441,\n",
              " 'songs': 442,\n",
              " 'space': 443,\n",
              " 'cat': 444,\n",
              " 'show': 445,\n",
              " 'build': 446,\n",
              " 'purpose': 447,\n",
              " 'design': 448,\n",
              " 'near': 449,\n",
              " 'kind': 450,\n",
              " 'bangalore': 451,\n",
              " 'period': 452,\n",
              " 'type': 453,\n",
              " 'such': 454,\n",
              " 'well': 455,\n",
              " 'able': 456,\n",
              " 'note': 457,\n",
              " 'services': 458,\n",
              " 'worst': 459,\n",
              " 'behind': 460,\n",
              " 'list': 461,\n",
              " 'majors': 462,\n",
              " 'websites': 463,\n",
              " 'call': 464,\n",
              " 'run': 465,\n",
              " 'seen': 466,\n",
              " '0': 467,\n",
              " 'reduce': 468,\n",
              " 'instead': 469,\n",
              " 'cause': 470,\n",
              " 'join': 471,\n",
              " 'technology': 472,\n",
              " 'asked': 473,\n",
              " 'post': 474,\n",
              " 'because': 475,\n",
              " 'current': 476,\n",
              " 'popular': 477,\n",
              " 'law': 478,\n",
              " 'differ': 479,\n",
              " 'wrong': 480,\n",
              " 'digital': 481,\n",
              " 'family': 482,\n",
              " 'date': 483,\n",
              " 'reason': 484,\n",
              " 'program': 485,\n",
              " 'private': 486,\n",
              " 'today': 487,\n",
              " 'height': 488,\n",
              " 'sentence': 489,\n",
              " 'civil': 490,\n",
              " 'ca': 491,\n",
              " 'degree': 492,\n",
              " 'choose': 493,\n",
              " 'management': 494,\n",
              " 'public': 495,\n",
              " 'easily': 496,\n",
              " '2000': 497,\n",
              " 'sleep': 498,\n",
              " 'air': 499,\n",
              " 'pregnant': 500,\n",
              " 'hate': 501,\n",
              " 'center': 502,\n",
              " 'biggest': 503,\n",
              " 'main': 504,\n",
              " 'visa': 505,\n",
              " 'stay': 506,\n",
              " 'facts': 507,\n",
              " 'traffic': 508,\n",
              " 'city': 509,\n",
              " 'causes': 510,\n",
              " 'apps': 511,\n",
              " 'down': 512,\n",
              " 'order': 513,\n",
              " 'apple': 514,\n",
              " 'times': 515,\n",
              " 'based': 516,\n",
              " 'both': 517,\n",
              " 'media': 518,\n",
              " 'international': 519,\n",
              " 'search': 520,\n",
              " 'sites': 521,\n",
              " 'death': 522,\n",
              " 'compared': 523,\n",
              " 'jee': 524,\n",
              " 'add': 525,\n",
              " \"it's\": 526,\n",
              " 'boyfriend': 527,\n",
              " 'small': 528,\n",
              " 'drug': 529,\n",
              " 'also': 530,\n",
              " 'python': 531,\n",
              " 'recover': 532,\n",
              " 'ms': 533,\n",
              " 'canada': 534,\n",
              " 'health': 535,\n",
              " 'iit': 536,\n",
              " 'successful': 537,\n",
              " 'gain': 538,\n",
              " 'decision': 539,\n",
              " 'indians': 540,\n",
              " 'currency': 541,\n",
              " 'benefits': 542,\n",
              " 'fast': 543,\n",
              " 'face': 544,\n",
              " 'machine': 545,\n",
              " 'wear': 546,\n",
              " 'house': 547,\n",
              " 'plan': 548,\n",
              " 'part': 549,\n",
              " 'given': 550,\n",
              " 'story': 551,\n",
              " 'fall': 552,\n",
              " 'startup': 553,\n",
              " 'products': 554,\n",
              " 'point': 555,\n",
              " 'videos': 556,\n",
              " 'stock': 557,\n",
              " 'less': 558,\n",
              " 'foreign': 559,\n",
              " 'battle': 560,\n",
              " 'preparation': 561,\n",
              " 'terms': 562,\n",
              " 'level': 563,\n",
              " 'created': 564,\n",
              " 'normal': 565,\n",
              " 'remove': 566,\n",
              " 'value': 567,\n",
              " 'dog': 568,\n",
              " 'move': 569,\n",
              " 'found': 570,\n",
              " '000': 571,\n",
              " 'medical': 572,\n",
              " 'legal': 573,\n",
              " 'amazon': 574,\n",
              " 'invest': 575,\n",
              " '20': 576,\n",
              " 'california': 577,\n",
              " 'project': 578,\n",
              " 'child': 579,\n",
              " 'form': 580,\n",
              " 'banning': 581,\n",
              " 'etc': 582,\n",
              " 'humans': 583,\n",
              " 'views': 584,\n",
              " 'rate': 585,\n",
              " 'ideas': 586,\n",
              " 'product': 587,\n",
              " 'ban': 588,\n",
              " 'coaching': 589,\n",
              " 'vote': 590,\n",
              " 'overcome': 591,\n",
              " 'known': 592,\n",
              " 'profile': 593,\n",
              " 'physics': 594,\n",
              " 'gate': 595,\n",
              " 'solar': 596,\n",
              " 'alcohol': 597,\n",
              " 'speak': 598,\n",
              " 'theory': 599,\n",
              " 'matter': 600,\n",
              " \"didn't\": 601,\n",
              " 'yourself': 602,\n",
              " 'drive': 603,\n",
              " 'called': 604,\n",
              " 'side': 605,\n",
              " 'uk': 606,\n",
              " 'snapchat': 607,\n",
              " 'ones': 608,\n",
              " 'again': 609,\n",
              " 'easiest': 610,\n",
              " 'ias': 611,\n",
              " 'hours': 612,\n",
              " '100': 613,\n",
              " 'grow': 614,\n",
              " 'research': 615,\n",
              " 'single': 616,\n",
              " '9': 617,\n",
              " 'effect': 618,\n",
              " 'week': 619,\n",
              " 'send': 620,\n",
              " 'talk': 621,\n",
              " 'correct': 622,\n",
              " 'pros': 623,\n",
              " 'others': 624,\n",
              " 'm': 625,\n",
              " 'must': 626,\n",
              " 'sell': 627,\n",
              " 'cons': 628,\n",
              " 'follow': 629,\n",
              " 'quality': 630,\n",
              " 'group': 631,\n",
              " 'easy': 632,\n",
              " 'lot': 633,\n",
              " 'porn': 634,\n",
              " 'germany': 635,\n",
              " 'faster': 636,\n",
              " 'information': 637,\n",
              " 'application': 638,\n",
              " 'famous': 639,\n",
              " 'credit': 640,\n",
              " 'marks': 641,\n",
              " 'night': 642,\n",
              " 'advice': 643,\n",
              " 'studying': 644,\n",
              " 'anything': 645,\n",
              " 'view': 646,\n",
              " 'distance': 647,\n",
              " 'australia': 648,\n",
              " 'solve': 649,\n",
              " 'mumbai': 650,\n",
              " 'field': 651,\n",
              " 'full': 652,\n",
              " 'bollywood': 653,\n",
              " 'marriage': 654,\n",
              " 'improvement': 655,\n",
              " 'guys': 656,\n",
              " 'sydney': 657,\n",
              " 'kill': 658,\n",
              " '2015': 659,\n",
              " 'required': 660,\n",
              " 'daily': 661,\n",
              " 'star': 662,\n",
              " '15': 663,\n",
              " 'low': 664,\n",
              " 'courses': 665,\n",
              " 'pro': 666,\n",
              " 'effective': 667,\n",
              " 'russia': 668,\n",
              " 'size': 669,\n",
              " 'short': 670,\n",
              " 'green': 671,\n",
              " 'institute': 672,\n",
              " 'problems': 673,\n",
              " 'messages': 674,\n",
              " 'force': 675,\n",
              " 'general': 676,\n",
              " 'put': 677,\n",
              " 'happy': 678,\n",
              " 'similar': 679,\n",
              " 'children': 680,\n",
              " 'left': 681,\n",
              " 'south': 682,\n",
              " 'desert': 683,\n",
              " 'provider': 684,\n",
              " '12': 685,\n",
              " 'options': 686,\n",
              " 'sim': 687,\n",
              " 'tax': 688,\n",
              " 'cell': 689,\n",
              " 'languages': 690,\n",
              " 'security': 691,\n",
              " 'source': 692,\n",
              " 'rupees': 693,\n",
              " 'advantages': 694,\n",
              " '30': 695,\n",
              " 'function': 696,\n",
              " 'set': 697,\n",
              " 'suitable': 698,\n",
              " 'those': 699,\n",
              " 'avoid': 700,\n",
              " 'investment': 701,\n",
              " 'industry': 702,\n",
              " 'started': 703,\n",
              " 'suicide': 704,\n",
              " 'message': 705,\n",
              " 'dream': 706,\n",
              " \"someone's\": 707,\n",
              " 'developer': 708,\n",
              " 'file': 709,\n",
              " 'healthy': 710,\n",
              " 'impact': 711,\n",
              " 'term': 712,\n",
              " 'safety': 713,\n",
              " 'uber': 714,\n",
              " 'lost': 715,\n",
              " 'photos': 716,\n",
              " 'deleted': 717,\n",
              " 'mass': 718,\n",
              " 'page': 719,\n",
              " 'beautiful': 720,\n",
              " 'pc': 721,\n",
              " 'says': 722,\n",
              " 'turn': 723,\n",
              " 'graduate': 724,\n",
              " 'blood': 725,\n",
              " 'three': 726,\n",
              " 'married': 727,\n",
              " 'area': 728,\n",
              " 'colleges': 729,\n",
              " 'jio': 730,\n",
              " 'often': 731,\n",
              " 'likes': 732,\n",
              " 'fix': 733,\n",
              " 'words': 734,\n",
              " 'exactly': 735,\n",
              " 'model': 736,\n",
              " 'ex': 737,\n",
              " 'iq': 738,\n",
              " 'party': 739,\n",
              " 'hindi': 740,\n",
              " 'oil': 741,\n",
              " 'care': 742,\n",
              " 'past': 743,\n",
              " 'few': 744,\n",
              " 'gay': 745,\n",
              " 'offer': 746,\n",
              " 'develop': 747,\n",
              " 'across': 748,\n",
              " \"isn't\": 749,\n",
              " 'price': 750,\n",
              " 'types': 751,\n",
              " 'letter': 752,\n",
              " 'chemical': 753,\n",
              " 'electrical': 754,\n",
              " 'check': 755,\n",
              " 'male': 756,\n",
              " 'japanese': 757,\n",
              " 'brain': 758,\n",
              " 'net': 759,\n",
              " 'north': 760,\n",
              " 'understand': 761,\n",
              " 'blog': 762,\n",
              " 'address': 763,\n",
              " 'cold': 764,\n",
              " 'engine': 765,\n",
              " 'office': 766,\n",
              " 'reasons': 767,\n",
              " 'text': 768,\n",
              " 'pass': 769,\n",
              " 'share': 770,\n",
              " 'coming': 771,\n",
              " 'leave': 772,\n",
              " 'eating': 773,\n",
              " 'picture': 774,\n",
              " 'japan': 775,\n",
              " 'heard': 776,\n",
              " 'second': 777,\n",
              " 'dogs': 778,\n",
              " 'related': 779,\n",
              " 'macbook': 780,\n",
              " 'late': 781,\n",
              " 'prime': 782,\n",
              " 'store': 783,\n",
              " 'enough': 784,\n",
              " 'female': 785,\n",
              " 'ios': 786,\n",
              " 'calculate': 787,\n",
              " 'fight': 788,\n",
              " 'line': 789,\n",
              " 'access': 790,\n",
              " 'chances': 791,\n",
              " 'meet': 792,\n",
              " 'red': 793,\n",
              " 'proposed': 794,\n",
              " 'training': 795,\n",
              " 'quickly': 796,\n",
              " 'contact': 797,\n",
              " 'loss': 798,\n",
              " 'team': 799,\n",
              " 'hyderabad': 800,\n",
              " 'taking': 801,\n",
              " 'county': 802,\n",
              " 'network': 803,\n",
              " 'topics': 804,\n",
              " 'americans': 805,\n",
              " 'convert': 806,\n",
              " 'moon': 807,\n",
              " 'mix': 808,\n",
              " 'numbers': 809,\n",
              " 'religion': 810,\n",
              " 'exams': 811,\n",
              " 'chance': 812,\n",
              " 'once': 813,\n",
              " 'basic': 814,\n",
              " 'narendra': 815,\n",
              " 'away': 816,\n",
              " 'political': 817,\n",
              " 'users': 818,\n",
              " 'british': 819,\n",
              " 'personal': 820,\n",
              " 'recruit': 821,\n",
              " 'penis': 822,\n",
              " 'national': 823,\n",
              " 'balance': 824,\n",
              " 'inr': 825,\n",
              " 'speaking': 826,\n",
              " 'paid': 827,\n",
              " 'said': 828,\n",
              " 'demonetization': 829,\n",
              " 'everyone': 830,\n",
              " 'rich': 831,\n",
              " 'communication': 832,\n",
              " 'rehab': 833,\n",
              " 'panel': 834,\n",
              " 'drink': 835,\n",
              " 'depression': 836,\n",
              " 'installation': 837,\n",
              " 'film': 838,\n",
              " 'blowing': 839,\n",
              " 'solution': 840,\n",
              " 'samsung': 841,\n",
              " 'changed': 842,\n",
              " 'pune': 843,\n",
              " 'wife': 844,\n",
              " 'boy': 845,\n",
              " 'precautions': 846,\n",
              " 'transfer': 847,\n",
              " 'belly': 848,\n",
              " 'everything': 849,\n",
              " 'gold': 850,\n",
              " 'taken': 851,\n",
              " 'n': 852,\n",
              " 'handling': 853,\n",
              " 'yes': 854,\n",
              " 'reading': 855,\n",
              " 'news': 856,\n",
              " 'following': 857,\n",
              " 'train': 858,\n",
              " 'explain': 859,\n",
              " 'blocked': 860,\n",
              " 'moment': 861,\n",
              " 'galaxy': 862,\n",
              " 'twitter': 863,\n",
              " 'animals': 864,\n",
              " 'army': 865,\n",
              " 'likely': 866,\n",
              " 'studies': 867,\n",
              " 'bill': 868,\n",
              " 'won': 869,\n",
              " 'earthquake': 870,\n",
              " 'paper': 871,\n",
              " 'since': 872,\n",
              " 'please': 873,\n",
              " 'smart': 874,\n",
              " 'try': 875,\n",
              " 'financial': 876,\n",
              " 'europe': 877,\n",
              " 'crush': 878,\n",
              " 'singapore': 879,\n",
              " 'grads': 880,\n",
              " 'hire': 881,\n",
              " '16': 882,\n",
              " 'obama': 883,\n",
              " 'resources': 884,\n",
              " 'corruption': 885,\n",
              " 'role': 886,\n",
              " 'option': 887,\n",
              " 'break': 888,\n",
              " 'hollywood': 889,\n",
              " 'scope': 890,\n",
              " 'within': 891,\n",
              " 'vs': 892,\n",
              " 'policy': 893,\n",
              " 'nra': 894,\n",
              " 'laws': 895,\n",
              " 'thinking': 896,\n",
              " 'currently': 897,\n",
              " 'shotguns': 898,\n",
              " 'diet': 899,\n",
              " 'season': 900,\n",
              " '50': 901,\n",
              " 'block': 902,\n",
              " 'dating': 903,\n",
              " 'determine': 904,\n",
              " 'difficult': 905,\n",
              " 'german': 906,\n",
              " 'screen': 907,\n",
              " 'knowledge': 908,\n",
              " 'color': 909,\n",
              " '11': 910,\n",
              " 'allowed': 911,\n",
              " 'structure': 912,\n",
              " 'already': 913,\n",
              " 'pain': 914,\n",
              " 'skin': 915,\n",
              " 'admission': 916,\n",
              " 'inpatient': 917,\n",
              " 'muslims': 918,\n",
              " 'pictures': 919,\n",
              " 'sun': 920,\n",
              " 'professional': 921,\n",
              " 'let': 922,\n",
              " 'amount': 923,\n",
              " 'least': 924,\n",
              " 'wants': 925,\n",
              " 'natural': 926,\n",
              " 'negative': 927,\n",
              " 'officer': 928,\n",
              " 'blue': 929,\n",
              " 'gift': 930,\n",
              " 'fake': 931,\n",
              " 'opinion': 932,\n",
              " 'infinite': 933,\n",
              " 'tools': 934,\n",
              " 'islam': 935,\n",
              " \"i've\": 936,\n",
              " 'muslim': 937,\n",
              " 'strategy': 938,\n",
              " 'significance': 939,\n",
              " 'interested': 940,\n",
              " 'personality': 941,\n",
              " 'linux': 942,\n",
              " 'estate': 943,\n",
              " 'useful': 944,\n",
              " \"you're\": 945,\n",
              " 'needing': 946,\n",
              " 'photo': 947,\n",
              " 'disadvantages': 948,\n",
              " 'moral': 949,\n",
              " 'board': 950,\n",
              " '18': 951,\n",
              " 'simple': 952,\n",
              " 'couples': 953,\n",
              " 'method': 954,\n",
              " 'capital': 955,\n",
              " 'track': 956,\n",
              " 'charge': 957,\n",
              " 'internship': 958,\n",
              " 'limit': 959,\n",
              " 'buying': 960,\n",
              " 'cut': 961,\n",
              " 'nuclear': 962,\n",
              " 'property': 963,\n",
              " 'income': 964,\n",
              " 'greatest': 965,\n",
              " 'smartphone': 966,\n",
              " 'sound': 967,\n",
              " 'due': 968,\n",
              " 'd': 969,\n",
              " 'visiting': 970,\n",
              " 'attack': 971,\n",
              " 'else': 972,\n",
              " 'fear': 973,\n",
              " 'microsoft': 974,\n",
              " 'starting': 975,\n",
              " 'written': 976,\n",
              " 'temperatures': 977,\n",
              " 'spend': 978,\n",
              " 'elections': 979,\n",
              " 'feeling': 980,\n",
              " 'inside': 981,\n",
              " 'french': 982,\n",
              " 'character': 983,\n",
              " 'shows': 984,\n",
              " 'final': 985,\n",
              " 'early': 986,\n",
              " 'little': 987,\n",
              " 'crack': 988,\n",
              " 'names': 989,\n",
              " 'military': 990,\n",
              " 'seo': 991,\n",
              " 'bring': 992,\n",
              " 'meth': 993,\n",
              " 'wifi': 994,\n",
              " 'kerala': 995,\n",
              " 'cards': 996,\n",
              " 'hand': 997,\n",
              " 'core': 998,\n",
              " 'followers': 999,\n",
              " 'close': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU_nlZ6EYvrh"
      },
      "source": [
        "## Creating embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD6d0T7aQC_8"
      },
      "source": [
        "embedding_index = {}\n",
        "\n",
        "with open('/content/drive/My Drive/glove.6B.200d.txt') as f :\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:], 'float32')\n",
        "        embedding_index[word] = vectors\n",
        "    f.close()\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLlCdz7DdLFc"
      },
      "source": [
        "embedding_matrix = np.random.random((len(word_index)+1, 200))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3EPr8jkdme6",
        "outputId": "4246c211-f85d-4358-fe9e-cea376f2cab9"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82195, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg1ZARYLYy4a"
      },
      "source": [
        "## Creating model architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt-1NCP6f78m"
      },
      "source": [
        "# Model for Q1\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model_q1 = tf.keras.Sequential()\n",
        "model_q1.add(Embedding(input_dim = len(word_index)+1,\n",
        "                       output_dim = 200,\n",
        "                      weights = [embedding_matrix],\n",
        "                      input_length = 30))\n",
        "model_q1.add(LSTM(128, activation = 'tanh', return_sequences = True))\n",
        "model_q1.add(Dropout(0.2))\n",
        "model_q1.add(LSTM(128, return_sequences = True))\n",
        "model_q1.add(LSTM(128))\n",
        "model_q1.add(Dense(60, activation = 'tanh'))\n",
        "model_q1.add(Dense(2, activation = 'sigmoid'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FtFPGKgBn3"
      },
      "source": [
        "# Model for Q2\n",
        "model_q2 = tf.keras.Sequential()\n",
        "model_q2.add(Embedding(input_dim = len(word_index)+1,\n",
        "                       output_dim = 200,\n",
        "                      weights = [embedding_matrix],\n",
        "                      input_length = 30))\n",
        "model_q2.add(LSTM(128, activation = 'tanh', return_sequences = True))\n",
        "model_q2.add(Dropout(0.2))\n",
        "model_q2.add(LSTM(128, return_sequences = True))\n",
        "model_q2.add(LSTM(128))\n",
        "model_q2.add(Dense(60, activation = 'tanh'))\n",
        "model_q2.add(Dense(2, activation = 'sigmoid'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUHCGAhagGHM"
      },
      "source": [
        "# Merging the output of the two models,i.e, model_q1 and model_q2\n",
        "mergedOut = Multiply()([model_q1.output, model_q2.output])\n",
        "\n",
        "mergedOut = Flatten()(mergedOut)\n",
        "mergedOut = Dense(100, activation = 'relu')(mergedOut)\n",
        "mergedOut = Dropout(0.2)(mergedOut)\n",
        "mergedOut = Dense(50, activation = 'relu')(mergedOut)\n",
        "mergedOut = Dropout(0.2)(mergedOut)\n",
        "mergedOut = Dense(2, activation = 'sigmoid')(mergedOut)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgv0jTj9Y5Nn"
      },
      "source": [
        "## Fitting with various parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM6UVHLqY9my"
      },
      "source": [
        "#### Adam with 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPaJOnqSgKpG",
        "outputId": "3cf7e307-a953-41db-bbac-4a8cd6dc1c7d"
      },
      "source": [
        "new_model = Model([model_q1.input, model_q2.input], mergedOut)\n",
        "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics = ['accuracy'])\n",
        "history = new_model.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 2, validation_data=([X_validate_q1, X_validate_q2], y_validate))\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "146/146 [==============================] - 1287s 9s/step - loss: 0.6677 - accuracy: 0.6144 - val_loss: 0.6323 - val_accuracy: 0.6305\n",
            "Epoch 2/2\n",
            "146/146 [==============================] - 1266s 9s/step - loss: 0.6200 - accuracy: 0.6516 - val_loss: 0.5994 - val_accuracy: 0.6783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aynlbG71Z0kn"
      },
      "source": [
        "#### Adam with 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ThMxF3aZvAW",
        "outputId": "6ef4d448-99fd-4b88-86eb-5fa2f9767120"
      },
      "source": [
        "new_model = Model([model_q1.input, model_q2.input], mergedOut)\n",
        "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics = ['accuracy'])\n",
        "history = new_model.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 5, validation_data=([X_validate_q1, X_validate_q2], y_validate))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "146/146 [==============================] - 1321s 9s/step - loss: 0.6641 - accuracy: 0.6206 - val_loss: 0.6591 - val_accuracy: 0.6305\n",
            "Epoch 2/5\n",
            "146/146 [==============================] - 1316s 9s/step - loss: 0.6598 - accuracy: 0.6298 - val_loss: 0.6590 - val_accuracy: 0.6305\n",
            "Epoch 3/5\n",
            "146/146 [==============================] - 1315s 9s/step - loss: 0.6588 - accuracy: 0.6311 - val_loss: 0.6441 - val_accuracy: 0.6305\n",
            "Epoch 4/5\n",
            "146/146 [==============================] - 1298s 9s/step - loss: 0.6514 - accuracy: 0.6299 - val_loss: 0.6280 - val_accuracy: 0.6305\n",
            "Epoch 5/5\n",
            "146/146 [==============================] - 1306s 9s/step - loss: 0.6230 - accuracy: 0.6348 - val_loss: 0.6079 - val_accuracy: 0.6790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Fgnal-Z3gh"
      },
      "source": [
        "#### Adam with 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnFFxF7QZeXc",
        "outputId": "f249488e-bb08-460f-f507-b9f3536388f2"
      },
      "source": [
        "\n",
        "\n",
        "new_model = Model([model_q1.input, model_q2.input], mergedOut)\n",
        "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics = ['accuracy'])\n",
        "history = new_model.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 20)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "162/162 [==============================] - 1295s 8s/step - loss: 0.6655 - accuracy: 0.6184\n",
            "Epoch 2/20\n",
            "162/162 [==============================] - 1297s 8s/step - loss: 0.6596 - accuracy: 0.6303\n",
            "Epoch 3/20\n",
            "162/162 [==============================] - 1283s 8s/step - loss: 0.6606 - accuracy: 0.6301\n",
            "Epoch 4/20\n",
            "162/162 [==============================] - 1292s 8s/step - loss: 0.6594 - accuracy: 0.6299\n",
            "Epoch 5/20\n",
            "162/162 [==============================] - 1303s 8s/step - loss: 0.6589 - accuracy: 0.6305\n",
            "Epoch 6/20\n",
            "162/162 [==============================] - 1279s 8s/step - loss: 0.6262 - accuracy: 0.6418\n",
            "Epoch 7/20\n",
            "162/162 [==============================] - 1247s 8s/step - loss: 0.5978 - accuracy: 0.6873\n",
            "Epoch 8/20\n",
            "162/162 [==============================] - 1279s 8s/step - loss: 0.5874 - accuracy: 0.6935\n",
            "Epoch 9/20\n",
            "162/162 [==============================] - 1271s 8s/step - loss: 0.5780 - accuracy: 0.6996\n",
            "Epoch 10/20\n",
            "162/162 [==============================] - 1278s 8s/step - loss: 0.5720 - accuracy: 0.7043\n",
            "Epoch 11/20\n",
            "162/162 [==============================] - 1276s 8s/step - loss: 0.5647 - accuracy: 0.7102\n",
            "Epoch 12/20\n",
            "162/162 [==============================] - 1289s 8s/step - loss: 0.5563 - accuracy: 0.7168\n",
            "Epoch 13/20\n",
            "162/162 [==============================] - 1274s 8s/step - loss: 0.5505 - accuracy: 0.7210\n",
            "Epoch 14/20\n",
            "162/162 [==============================] - 1294s 8s/step - loss: 0.5429 - accuracy: 0.7272\n",
            "Epoch 15/20\n",
            "162/162 [==============================] - 1281s 8s/step - loss: 0.5364 - accuracy: 0.7299\n",
            "Epoch 16/20\n",
            "162/162 [==============================] - 1263s 8s/step - loss: 0.5290 - accuracy: 0.7362\n",
            "Epoch 17/20\n",
            "162/162 [==============================] - 1263s 8s/step - loss: 0.5242 - accuracy: 0.7397\n",
            "Epoch 18/20\n",
            "162/162 [==============================] - 1270s 8s/step - loss: 0.5157 - accuracy: 0.7454\n",
            "Epoch 19/20\n",
            "162/162 [==============================] - 1279s 8s/step - loss: 0.5090 - accuracy: 0.7507\n",
            "Epoch 20/20\n",
            "162/162 [==============================] - 1276s 8s/step - loss: 0.5027 - accuracy: 0.7534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFsWmGvBZ73S"
      },
      "source": [
        "### Testing accuracy with 20 epochs in Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPB-kACkZeXf",
        "outputId": "99d71129-e86f-41eb-e81c-2d1bb9a59042"
      },
      "source": [
        "test_loss, test_acc = new_model.evaluate([X_test_q1, X_test_q2], y_test)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2528/2528 [==============================] - 172s 67ms/step - loss: 0.5503 - accuracy: 0.7284\n",
            "Test Loss: 0.5502656102180481\n",
            "Test Accuracy: 0.7284317016601562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW5CtTGNZDgm"
      },
      "source": [
        "#### SGD with 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcJi5KM17a60",
        "outputId": "10f48a75-2644-4660-fdd8-7a77ee2a9801"
      },
      "source": [
        "new_model2 = Model([model_q1.input, model_q2.input], mergedOut)\n",
        "new_model2.compile(optimizer = 'SGD', loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics = ['accuracy'])\n",
        "history2 = new_model2.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 2, validation_data=([X_validate_q1, X_validate_q2], y_validate))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "146/146 [==============================] - 1261s 9s/step - loss: 0.5984 - accuracy: 0.6818 - val_loss: 0.5972 - val_accuracy: 0.6819\n",
            "Epoch 2/2\n",
            "146/146 [==============================] - 1231s 8s/step - loss: 0.5972 - accuracy: 0.6831 - val_loss: 0.5969 - val_accuracy: 0.6817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8uGAbK7ZQLw"
      },
      "source": [
        "### SGD with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI5BBQfPfPYD",
        "outputId": "24cd91d4-91da-4116-f5a0-d24cacf16062"
      },
      "source": [
        "new_model3 = Model([model_q1.input, model_q2.input], mergedOut)\n",
        "new_model3.compile(optimizer = 'SGD', loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics = ['accuracy'])\n",
        "history3 = new_model2.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 10, validation_data=([X_validate_q1, X_validate_q2], y_validate))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "146/146 [==============================] - 1246s 9s/step - loss: 0.5976 - accuracy: 0.6831 - val_loss: 0.5967 - val_accuracy: 0.6823\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 1252s 9s/step - loss: 0.5974 - accuracy: 0.6834 - val_loss: 0.5966 - val_accuracy: 0.6813\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 1255s 9s/step - loss: 0.5973 - accuracy: 0.6836 - val_loss: 0.5965 - val_accuracy: 0.6821\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 1243s 9s/step - loss: 0.5971 - accuracy: 0.6838 - val_loss: 0.5964 - val_accuracy: 0.6820\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 1244s 9s/step - loss: 0.5970 - accuracy: 0.6832 - val_loss: 0.5963 - val_accuracy: 0.6822\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 1232s 8s/step - loss: 0.5970 - accuracy: 0.6835 - val_loss: 0.5962 - val_accuracy: 0.6820\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 1233s 8s/step - loss: 0.5969 - accuracy: 0.6837 - val_loss: 0.5962 - val_accuracy: 0.6821\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 1236s 8s/step - loss: 0.5968 - accuracy: 0.6836 - val_loss: 0.5961 - val_accuracy: 0.6821\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 1236s 8s/step - loss: 0.5968 - accuracy: 0.6838 - val_loss: 0.5961 - val_accuracy: 0.6822\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 1251s 9s/step - loss: 0.5965 - accuracy: 0.6834 - val_loss: 0.5960 - val_accuracy: 0.6822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x70a21gaFaR"
      },
      "source": [
        "### Testing accuracy with 10 epochs in SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyUktuLqFK_Y",
        "outputId": "98c50abf-5b41-4708-f91c-39d73e90e8f2"
      },
      "source": [
        "test_loss, test_acc = new_model2.evaluate([X_test_q1, X_test_q2], y_test)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1264/1264 [==============================] - 81s 64ms/step - loss: 0.5923 - accuracy: 0.6858\n",
            "Test Loss: 0.5923463702201843\n",
            "Test Accuracy: 0.685799777507782\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}