{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMVhedMDCJ7W"
      },
      "source": [
        "# CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbV_r9QRIypq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88879550-36d8-4cc2-e36c-af7989861906"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3izoFU1kRPrq"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omFH7YA9Jap_"
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras, nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_wGdRHv8Y3Z"
      },
      "source": [
        "import pickle\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y067WBZRXcQ"
      },
      "source": [
        "## Data Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7d-D65RIqVN"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/SMAI_QUORA/questions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpEGCdu-CI6t",
        "outputId": "2a50da9b-326e-49a3-cdee-8e9b246a9b11"
      },
      "source": [
        "#changing pwd to desired directory\n",
        "%cd '/content/drive/MyDrive/SMAI_QUORA'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/SMAI_QUORA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGwrEUVIRu33"
      },
      "source": [
        "## Getting Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPoyYekiCLNB",
        "outputId": "f93cd7dd-7ba3-40c7-cece-c5c3b963de74"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 15:14:27--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2021-04-28 15:14:27--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2021-04-28 15:14:28--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  4.92MB/s    in 6m 51s  \n",
            "\n",
            "2021-04-28 15:21:19 (5.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEJ4tDZ2CT9T",
        "outputId": "ea1c233f-eb1b-488c-9790-5cdad1290a93"
      },
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "replace glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.840B.300d.txt     \n",
            "\n",
            "y\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwlsGNBoRzpZ"
      },
      "source": [
        "## Embedding Vector Using Glove\n",
        "- Creating embedding_vector in form of dictionary and saving it for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZgu0fiGDadV"
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "def get_embedding_vector(file_name):\n",
        "  embedding_vector = {}\n",
        "\n",
        "  with open(file_name) as f :\n",
        "    for line in tqdm(f):\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding_vector[word] = np.array(values[1:], dtype='float32')\n",
        "    # f.close()\n",
        "  return embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW2cokQQF75r",
        "outputId": "2a8b5eff-a345-4cac-b73e-981ad705bf36"
      },
      "source": [
        "embedding_vector = get_embedding_vector('glove.840B.300d.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196017it [05:41, 6430.88it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQcqMpz8ZAeN"
      },
      "source": [
        "np.save('my_embedding_vector.npy', embedding_vector) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-m4rVqWZZ9Z"
      },
      "source": [
        "embedding_vector = np.load('my_embedding_vector.npy',allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE8JNdQ1SL2P"
      },
      "source": [
        "## Cleaning Questions \n",
        "- Cleaning `question1` and `question2` of dataframe. \n",
        "- Removing stopwords and using regex "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fOlwHyPI1-W",
        "outputId": "789da3a6-3d1d-42b5-eb11-11914a70b890"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1IQ5W1AAWPL"
      },
      "source": [
        "\n",
        "def review_to_wordlist(review, remove_stopwords=True):\n",
        "  if(type(review) is str):\n",
        "    words = review.lower().split()\n",
        "  else:\n",
        "    words = str(review).lower().split()\n",
        "  if remove_stopwords:\n",
        "      stops = set(stopwords.words(\"english\"))\n",
        "      words = [w for w in words if not w in stops]\n",
        "  \n",
        "    \n",
        "  review_text = \" \".join(words)\n",
        "  review_text = re.sub(r\"[^A-Za-z0-9(),!.?\\'\\`]\", \" \", review_text)\n",
        "  review_text = re.sub(r\"\\'s\", \" 's \", review_text)\n",
        "  review_text = re.sub(r\"\\'ve\", \" 've \", review_text)\n",
        "  review_text = re.sub(r\"n\\'t\", \" 't \", review_text)\n",
        "  review_text = re.sub(r\"\\'re\", \" 're \", review_text)\n",
        "  review_text = re.sub(r\"\\'d\", \" 'd \", review_text)\n",
        "  review_text = re.sub(r\"\\'ll\", \" 'll \", review_text)\n",
        "  review_text = re.sub(r\",\", \" \", review_text)\n",
        "  review_text = re.sub(r\"\\.\", \" \", review_text)\n",
        "  review_text = re.sub(r\"!\", \" \", review_text)\n",
        "  review_text = re.sub(r\"\\(\", \" ( \", review_text)\n",
        "  review_text = re.sub(r\"\\)\", \" ) \", review_text)\n",
        "  review_text = re.sub(r\"\\?\", \" \", review_text)\n",
        "  review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
        "  \n",
        "  words = review_text.split()\n",
        "  # Shorten words to their stems\n",
        "  stemmer = SnowballStemmer('english')\n",
        "  stemmed_words = [stemmer.stem(word) for word in words]\n",
        "  \n",
        "  review_text = \" \".join(stemmed_words)\n",
        "  \n",
        "  # Return a list of words\n",
        "  return(review_text)\n",
        "\n",
        "def process_questions(question_list, questions, question_list_name):\n",
        "# function to transform questions and display progress\n",
        "  for question in questions:\n",
        "    question_list.append(review_to_wordlist(question))\n",
        "    if len(question_list) % 100000 == 0:\n",
        "      progress = len(question_list)/len(df) * 100\n",
        "      print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))\n",
        "\n",
        "  print(\"{} is {}% complete.\".format(question_list_name, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_K7uzkIODX",
        "outputId": "5f37917e-2df6-4884-eaff-90d5f1199d89"
      },
      "source": [
        "questions1 = []     \n",
        "process_questions(questions1, df.question1, \"questions1\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "questions1 is 24.7% complete.\n",
            "questions1 is 49.5% complete.\n",
            "questions1 is 74.2% complete.\n",
            "questions1 is 98.9% complete.\n",
            "questions1 is 100% complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW0D1d79Ia-7",
        "outputId": "cf1af203-709c-4811-a3ab-b81feef515f9"
      },
      "source": [
        "questions2 = []     \n",
        "process_questions(questions2, df.question2, \"questions2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "questions2 is 24.7% complete.\n",
            "questions2 is 49.5% complete.\n",
            "questions2 is 74.2% complete.\n",
            "questions2 is 98.9% complete.\n",
            "questions2 is 100% complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbqK0IqsSk0n"
      },
      "source": [
        "## Getting feature matrix of pre-processed `question1` and `question2`   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBzkf16JQid"
      },
      "source": [
        "def get_qfeature_matrix(questions):\n",
        "  que = [nltk.word_tokenize(ww) for ww in questions]\n",
        "  que_feats = np.zeros((len(que),300))\n",
        "  for i, question in enumerate(que):\n",
        "    temp_matrix = np.zeros((1,300), dtype='float32')\n",
        "    for j, word in enumerate(question):\n",
        "      embed_value = embedding_vector.get(word)\n",
        "      if(embed_value is not None):\n",
        "        temp_matrix = np.add(temp_matrix,embed_value.reshape(1,300),dtype='float32')\n",
        "    if(i%20000 == 0):\n",
        "      print(\"{} done\".format(20000*i))\n",
        "    \n",
        "    que_feats[i] = temp_matrix\n",
        "  \n",
        "  del(que)\n",
        "  return que_feats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ4eRreJR1lu",
        "outputId": "e7d2985a-6e48-41e9-d41e-eff9325e9cd2"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97PGpztRRZK8",
        "outputId": "30b041ae-e5c3-464c-e0fd-be7c1ddbdf29"
      },
      "source": [
        "que1_feats = get_qfeature_matrix(questions1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 done\n",
            "400000000 done\n",
            "800000000 done\n",
            "1200000000 done\n",
            "1600000000 done\n",
            "2000000000 done\n",
            "2400000000 done\n",
            "2800000000 done\n",
            "3200000000 done\n",
            "3600000000 done\n",
            "4000000000 done\n",
            "4400000000 done\n",
            "4800000000 done\n",
            "5200000000 done\n",
            "5600000000 done\n",
            "6000000000 done\n",
            "6400000000 done\n",
            "6800000000 done\n",
            "7200000000 done\n",
            "7600000000 done\n",
            "8000000000 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubt4mLf7RkM-",
        "outputId": "7d8ef903-1932-4988-ab67-77452c382c83"
      },
      "source": [
        "que2_feats = get_qfeature_matrix(questions2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 done\n",
            "400000000 done\n",
            "800000000 done\n",
            "1200000000 done\n",
            "1600000000 done\n",
            "2000000000 done\n",
            "2400000000 done\n",
            "2800000000 done\n",
            "3200000000 done\n",
            "3600000000 done\n",
            "4000000000 done\n",
            "4400000000 done\n",
            "4800000000 done\n",
            "5200000000 done\n",
            "5600000000 done\n",
            "6000000000 done\n",
            "6400000000 done\n",
            "6800000000 done\n",
            "7200000000 done\n",
            "7600000000 done\n",
            "8000000000 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT9N3ZPVdhww"
      },
      "source": [
        "del(questions1)\n",
        "del(questions2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHe9M9gieHJs"
      },
      "source": [
        "np.save('my_que1_feats.npy', que1_feats) \n",
        "np.save('my_que2_feats.npy', que2_feats) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVl-hN7MgBfp"
      },
      "source": [
        "que1_feats = np.load('my_que1_feats.npy',allow_pickle='TRUE')\n",
        "que2_feats = np.load('my_que2_feats.npy',allow_pickle='TRUE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvJ6KZrvbG3R"
      },
      "source": [
        "## Concatenated Matrices\n",
        "- Creating `difference and hadamard feature matrices` as per paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1igajqjbBe2"
      },
      "source": [
        "diff_feats = que1_feats - que2_feats\n",
        "hadamard_feats = que1_feats * que2_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKrNkkCDfeJZ"
      },
      "source": [
        "features = np.hstack((np.hstack((que1_feats,que2_feats)),np.hstack((diff_feats,hadamard_feats))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87s_pV4Hb3Il"
      },
      "source": [
        "del(que1_feats)\n",
        "del(que2_feats)\n",
        "del(diff_feats)\n",
        "del(hadamard_feats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKMcYjk0hCoM"
      },
      "source": [
        "np.save('my_features.npy', features) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB3H8bYUhPnw"
      },
      "source": [
        "features = np.load('my_features.npy',allow_pickle='TRUE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uErvsf1hZme"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_bkJLMdUJ7P"
      },
      "source": [
        "#### Splitting into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OqZDqQLj3kH"
      },
      "source": [
        "labels = df[\"is_duplicate\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6V22TLskP5J"
      },
      "source": [
        "Y = np.array(labels)\n",
        "Y = Y.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dprO8B4gkJxQ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, Y, train_size = 0.7,random_state = 42, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kMFThKtigFL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "import time\n",
        "from keras.layers import BatchNormalization\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj6jTj8NTPbs"
      },
      "source": [
        "### Model1 using SGD optimizer\n",
        "- This model has 3 dense layers with dropout of 10%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRevSM5JhY4F"
      },
      "source": [
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(200,input_dim=1200))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(100))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(50))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(2,activation='softmax'))\n",
        "  opt = SGD(lr=0.001, momentum=0.9) \n",
        "\n",
        "  model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzk_4Jc2lGSi",
        "outputId": "f9ea5397-ccd3-4de6-b9e3-082d3a6e47f2"
      },
      "source": [
        "\n",
        "def task1_run():\n",
        "  task1model = get_model()\n",
        "  start = time.time()\n",
        "  history = task1model.fit(x_train,y_train,epochs=50, batch_size=2000, verbose=1)\n",
        "  end = time.time()\n",
        "  print(\"Model took %0.2f seconds to train\"%(end - start))\n",
        "  \n",
        "  return task1model, history\n",
        "\n",
        "task1model, task1history = task1_run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "142/142 [==============================] - 10s 63ms/step - loss: 0.8273 - accuracy: 0.5873\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.6338 - accuracy: 0.6285\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.6172 - accuracy: 0.6397\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.6029 - accuracy: 0.6509\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5914 - accuracy: 0.6611\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 11s 77ms/step - loss: 0.5805 - accuracy: 0.6719\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5717 - accuracy: 0.6810\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5635 - accuracy: 0.6871\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5569 - accuracy: 0.6924\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 12s 84ms/step - loss: 0.5518 - accuracy: 0.6969\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5465 - accuracy: 0.6997\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5399 - accuracy: 0.7056\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5384 - accuracy: 0.7075\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5334 - accuracy: 0.7124\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 9s 65ms/step - loss: 0.5301 - accuracy: 0.7131\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.5294 - accuracy: 0.7136\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5253 - accuracy: 0.7196\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5229 - accuracy: 0.7196\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5201 - accuracy: 0.7207\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.5181 - accuracy: 0.7218\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 9s 65ms/step - loss: 0.5168 - accuracy: 0.7241\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 10s 68ms/step - loss: 0.5147 - accuracy: 0.7260\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.5133 - accuracy: 0.7262\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5114 - accuracy: 0.7289\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5099 - accuracy: 0.7293\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5073 - accuracy: 0.7316\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.5067 - accuracy: 0.7315\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 11s 74ms/step - loss: 0.5059 - accuracy: 0.7315\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5038 - accuracy: 0.7343\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.5009 - accuracy: 0.7353\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 12s 84ms/step - loss: 0.5015 - accuracy: 0.7362\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 12s 82ms/step - loss: 0.5010 - accuracy: 0.7364\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 11s 81ms/step - loss: 0.4996 - accuracy: 0.7369\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.4969 - accuracy: 0.7375\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.4965 - accuracy: 0.7380\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.4936 - accuracy: 0.7392\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 10s 71ms/step - loss: 0.4925 - accuracy: 0.7425\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4915 - accuracy: 0.7439\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4909 - accuracy: 0.7436\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4895 - accuracy: 0.7447\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4885 - accuracy: 0.7442\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4872 - accuracy: 0.7461\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4859 - accuracy: 0.7460\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4854 - accuracy: 0.7476\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4854 - accuracy: 0.7471\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 9s 67ms/step - loss: 0.4839 - accuracy: 0.7472\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4822 - accuracy: 0.7495\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4821 - accuracy: 0.7492\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4815 - accuracy: 0.7499\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 10s 70ms/step - loss: 0.4825 - accuracy: 0.7495\n",
            "Model took 504.50 seconds to train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whMFXLAalwrk",
        "outputId": "980da45a-4983-4b64-9095-c149ed60c5dc"
      },
      "source": [
        "def task1_evaluate(model):\n",
        "  _,acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return acc *100\n",
        "  \n",
        "print(\"Accuracy: %0.2f\"%task1_evaluate(task1model)+\"%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 75.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnWHnnRATY6x"
      },
      "source": [
        "### Model2 using adam optimizer\n",
        "- This model has 3 dense layers with dropout of 10%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMKJuhEenwcC"
      },
      "source": [
        "def get_model2():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(200,input_dim=1200))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(100))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(50))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(2,activation='softmax'))\n",
        "  # opt = SGD(lr=0.001, momentum=0.9) \n",
        "\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ErKivXTn7eC",
        "outputId": "da11446e-9ccc-4bbc-98b0-0a5fe83657d4"
      },
      "source": [
        "def task2_run():\n",
        "  task2model = get_model2()\n",
        "  start = time.time()\n",
        "  history = task2model.fit(x_train,y_train,epochs=50, batch_size=2000, verbose=1)\n",
        "  end = time.time()\n",
        "  print(\"Model took %0.2f seconds to train\"%(end - start))\n",
        "  \n",
        "  return task2model, history\n",
        "\n",
        "task2model, task2history = task2_run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "142/142 [==============================] - 14s 82ms/step - loss: 0.8434 - accuracy: 0.6315\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 12s 81ms/step - loss: 0.5049 - accuracy: 0.7327\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 12s 82ms/step - loss: 0.4692 - accuracy: 0.7577\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 11s 79ms/step - loss: 0.4429 - accuracy: 0.7753\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.4196 - accuracy: 0.7907\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.4002 - accuracy: 0.8045\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.3809 - accuracy: 0.8152\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.3642 - accuracy: 0.8263\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.3463 - accuracy: 0.8372\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.3311 - accuracy: 0.8451\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.3173 - accuracy: 0.8537\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.3031 - accuracy: 0.8613\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.2895 - accuracy: 0.8672\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.2768 - accuracy: 0.8748\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.2688 - accuracy: 0.8786\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.2584 - accuracy: 0.8839\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.2497 - accuracy: 0.8879\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 11s 78ms/step - loss: 0.2430 - accuracy: 0.8922\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 12s 84ms/step - loss: 0.2364 - accuracy: 0.8955\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.2290 - accuracy: 0.8997\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.2218 - accuracy: 0.9030\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.2181 - accuracy: 0.9044\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.2110 - accuracy: 0.9083\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 12s 86ms/step - loss: 0.2068 - accuracy: 0.9099\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 12s 85ms/step - loss: 0.2022 - accuracy: 0.9128\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1947 - accuracy: 0.9166\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1886 - accuracy: 0.9195\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1863 - accuracy: 0.9210\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1834 - accuracy: 0.9225\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1776 - accuracy: 0.9245\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1749 - accuracy: 0.9265\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1705 - accuracy: 0.9286\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1690 - accuracy: 0.9294\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1651 - accuracy: 0.9314\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1612 - accuracy: 0.9325\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1571 - accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1568 - accuracy: 0.9352\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.1547 - accuracy: 0.9362\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 9s 63ms/step - loss: 0.1516 - accuracy: 0.9377\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 11s 74ms/step - loss: 0.1473 - accuracy: 0.9402\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1485 - accuracy: 0.9397\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1462 - accuracy: 0.9404\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 12s 84ms/step - loss: 0.1445 - accuracy: 0.9411\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1414 - accuracy: 0.9426\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1393 - accuracy: 0.9437\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1370 - accuracy: 0.9445\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 12s 84ms/step - loss: 0.1342 - accuracy: 0.9455\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 12s 83ms/step - loss: 0.1346 - accuracy: 0.9456\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 10s 68ms/step - loss: 0.1310 - accuracy: 0.9478\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 9s 64ms/step - loss: 0.1277 - accuracy: 0.9491\n",
            "Model took 514.92 seconds to train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMFTaqMVTiGf"
      },
      "source": [
        "#### Highest Accuracy(Model2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2dDLXy6oGWv",
        "outputId": "638bb951-975f-4d5f-bc8e-a5a1236ee6cc"
      },
      "source": [
        "def task2_evaluate(model):\n",
        "  _,acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return acc *100\n",
        "  \n",
        "print(\"Accuracy: %0.2f\"%task2_evaluate(task2model)+\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 79.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qDbB0rATm-_"
      },
      "source": [
        "#### F1 Score(Model2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVM-zzUetlvQ",
        "outputId": "bf61cb89-b1c2-45d2-8c45-58520128aec7"
      },
      "source": [
        "pred2 = task2model.predict(x_test,batch_size=200,verbose=1)\n",
        "pred2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "607/607 [==============================] - 3s 4ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7753239e-01, 2.2467602e-02],\n",
              "       [9.8132312e-01, 1.8676842e-02],\n",
              "       [1.0000000e+00, 5.2981446e-11],\n",
              "       ...,\n",
              "       [5.5673052e-02, 9.4432694e-01],\n",
              "       [1.9539918e-01, 8.0460083e-01],\n",
              "       [7.2344966e-02, 9.2765498e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMJfUO5PtlvT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def get_ypred(pred):\n",
        "  y_pred = []\n",
        "  for row in pred:\n",
        "    y_pred.append(0 if row[0]>row[1] else 1)\n",
        "  \n",
        "  return np.array(y_pred).reshape(-1,1)\n",
        "\n",
        "y_pred2 = get_ypred(pred2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P903YSktxHW",
        "outputId": "51e14b63-9cd9-437f-fe02-c0dc70fe95ef"
      },
      "source": [
        "F1_score = f1_score(y_test,y_pred2,average='weighted')\n",
        "print(\"F1 Score: \",F1_score*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score:  79.8974611727898\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}